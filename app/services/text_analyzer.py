# Service d'analyse de texte

from app.models.fake_news_detector import FakeNewsDetector
from app.services.fact_checker import FactChecker
from typing import Dict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TextAnalyzer:
    def __init__(self):
        self.detector = FakeNewsDetector()
        self.fact_checker = FactChecker()
        logger.info("TextAnalyzer initialis√©")
    
    def analyze(self, text: str) -> Dict:
        """
        Analyse un texte pour d√©tecter la d√©sinformation
        
        Args:
            text: Le texte √† analyser
            
        Returns:
            Dictionnaire avec les r√©sultats de l'analyse
        """
        try:
            # D√©tection de fake news
            detection_result = self.detector.detect_fake_news(text)
            
            # V√©rification contre faits connus (priorit√©)
            known_facts_check = self.fact_checker.check_against_known_facts(text)
            
            # V√©rification de faits (fact-checking web)
            fact_check = self.fact_checker.verify_fact(text)
            
            # Analyse de sentiment (pour d√©tecter les biais)
            sentiment = self._analyze_sentiment(text)
            
            # M√©triques du texte
            metrics = self._calculate_metrics(text)
            
            # Ajuster le score de d√©tection avec la v√©rification de faits
            # PRIORIT√â √† la recherche web (fact_check), puis faits connus comme fallback
            if fact_check.get("verified") is False and fact_check.get("confidence", 0) > 0.5:
                # V√©rifi√© comme FAUX par recherche web
                detection_result["confidence"] = min(1.0, detection_result["confidence"] + 0.3)
                detection_result["is_fake"] = True
                detection_result["verdict"] = "fake"
                detection_result["reliability"] = (1.0 - detection_result["confidence"]) * 100
            elif fact_check.get("verified") is True and fact_check.get("confidence", 0) > 0.5:
                # V√©rifi√© comme VRAI par recherche web
                detection_result["confidence"] = max(0.0, detection_result["confidence"] - 0.35)
                detection_result["is_fake"] = False
                detection_result["verdict"] = "probablement_vrai"
                detection_result["reliability"] = (1.0 - detection_result["confidence"]) * 100
            elif known_facts_check.get("verified_as_true"):
                # Fallback : fait connu v√©rifi√© (seulement si recherche web n'a pas donn√© de r√©sultat)
                detection_result["confidence"] = max(0.0, detection_result["confidence"] - 0.3)
                detection_result["is_fake"] = False
                detection_result["verdict"] = "probablement_vrai"
                detection_result["reliability"] = (1.0 - detection_result["confidence"]) * 100
            elif known_facts_check.get("verified_as_false"):
                # Fallback : fait connu comme faux
                detection_result["confidence"] = min(1.0, detection_result["confidence"] + 0.25)
                detection_result["is_fake"] = True
                detection_result["verdict"] = "fake"
                detection_result["reliability"] = (1.0 - detection_result["confidence"]) * 100
            
            # Recalculer la fiabilit√©
            detection_result["reliability"] = (1.0 - detection_result["confidence"]) * 100
            
            return {
                "type": "text",
                "input": text[:200] + "..." if len(text) > 200 else text,
                "detection": detection_result,
                "fact_check": fact_check,
                "known_facts": known_facts_check,
                "sentiment": sentiment,
                "metrics": metrics,
                "recommendation": self._generate_recommendation(detection_result, sentiment, fact_check, known_facts_check)
            }
        
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du texte: {e}")
            raise
    
    def _analyze_sentiment(self, text: str) -> Dict:
        # Analyse simple bas√©e sur des mots-cl√©s
        text_lower = text.lower()
        
        positive_words = ['good', 'great', 'excellent', 'positive', 'success', 'happy']
        negative_words = ['bad', 'terrible', 'awful', 'negative', 'failure', 'sad', 'horrible']
        neutral_words = ['fact', 'information', 'data', 'report', 'study']
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        neutral_count = sum(1 for word in neutral_words if word in text_lower)
        
        total = positive_count + negative_count + neutral_count
        if total == 0:
            sentiment = "neutral"
            score = 0.5
        elif positive_count > negative_count:
            sentiment = "positive"
            score = 0.5 + (positive_count / max(total, 1)) * 0.3
        elif negative_count > positive_count:
            sentiment = "negative"
            score = 0.5 - (negative_count / max(total, 1)) * 0.3
        else:
            sentiment = "neutral"
            score = 0.5
        
        return {
            "label": sentiment,
            "score": float(score),
            "bias_detected": abs(score - 0.5) > 0.3
        }
    
    def _calculate_metrics(self, text: str) -> Dict:
        words = text.split()
        sentences = text.split('.')
        
        return {
            "word_count": len(words),
            "sentence_count": len([s for s in sentences if s.strip()]),
            "avg_words_per_sentence": len(words) / max(len([s for s in sentences if s.strip()]), 1),
            "char_count": len(text),
            "readability": "facile" if len(words) < 20 else "moyen" if len(words) < 50 else "complexe"
        }
    
    def _generate_recommendation(self, detection: Dict, sentiment: Dict, fact_check: Dict = None, known_facts: Dict = None) -> str:
        recommendations = []
        
        # PRIORIT√â √† la recherche web (fact_check)
        if fact_check and fact_check.get("verified") is False:
            recommendations.append(f"üî¥ Information v√©rifi√©e comme FAUSSE par recherche web (confiance: {fact_check.get('confidence', 0)*100:.0f}%).")
        elif fact_check and fact_check.get("verified") is True:
            recommendations.append(f"‚úÖ Information v√©rifi√©e comme VRAIE par recherche web (confiance: {fact_check.get('confidence', 0)*100:.0f}%).")
        elif fact_check and fact_check.get("sources_found", 0) > 0:
            recommendations.append(f"‚ÑπÔ∏è {fact_check.get('sources_found', 0)} source(s) fiable(s) trouv√©e(s) mais verdict incertain.")
        # Fallback : faits connus (seulement si recherche web n'a pas fonctionn√©)
        elif known_facts and known_facts.get("verified_as_true"):
            recommendations.append("‚úÖ Information v√©rifi√©e comme VRAIE (base de faits - recherche web indisponible).")
        elif known_facts and known_facts.get("verified_as_false"):
            recommendations.append("üî¥ Information v√©rifi√©e comme FAUSSE (base de faits - recherche web indisponible).")
        
        if detection['is_fake']:
            recommendations.append("‚ö†Ô∏è Ce contenu pr√©sente des signes de d√©sinformation. V√©rifiez les sources.")
        elif detection['confidence'] > 0.5:
            recommendations.append("‚ö†Ô∏è Ce contenu n√©cessite une v√©rification approfondie.")
        elif sentiment['bias_detected']:
            recommendations.append("‚ÑπÔ∏è Ce contenu pr√©sente un biais √©motionnel.")
        else:
            recommendations.append("‚úì Ce contenu semble fiable, mais restez critique.")
        
        return " ".join(recommendations) if recommendations else "‚ÑπÔ∏è Analyse effectu√©e."

